# Claude Code Metrics Dashboard Specification

## Executive Summary

This specification defines a comprehensive Grafana dashboard for monitoring Claude Code usage, performance, costs, and productivity. The dashboard provides real-time visibility into how Claude Code is being used, with emphasis on tool execution reliability, subagent utilization, error analysis, and cost optimization.

## Table of Contents

1. [Architecture Overview](#1-architecture-overview)
2. [Data Sources & Collection](#2-data-sources--collection)
3. [Dashboard Sections](#3-dashboard-sections)
4. [Metric Definitions](#4-metric-definitions)
5. [Panel Specifications](#5-panel-specifications)
6. [Alerting Rules](#6-alerting-rules)
7. [Implementation Guide](#7-implementation-guide)

---

## 1. Architecture Overview

### 1.1 Data Flow

```
┌─────────────────┐     ┌──────────────────────┐     ┌─────────────────┐
│   Claude Code   │────▶│  OpenTelemetry       │────▶│   Prometheus    │
│   (CLI/IDE)     │     │  Collector           │     │   (Metrics)     │
└─────────────────┘     └──────────────────────┘     └─────────────────┘
                                  │                           │
                                  ▼                           ▼
                        ┌─────────────────┐         ┌─────────────────┐
                        │      Loki       │         │     Grafana     │
                        │   (Logs/Events) │────────▶│   (Dashboard)   │
                        └─────────────────┘         └─────────────────┘
```

### 1.2 Components

| Component | Purpose | Protocol |
|-----------|---------|----------|
| Claude Code | Emits telemetry via OTEL | OTLP (gRPC/HTTP) |
| OTEL Collector | Receives, processes, exports signals | OTLP, Prometheus |
| Prometheus | Stores time-series metrics | PromQL |
| Loki | Stores structured event logs | LogQL |
| Grafana | Visualization and alerting | - |

### 1.3 Environment Configuration

```bash
# Required
export CLAUDE_CODE_ENABLE_TELEMETRY=1
export OTEL_METRICS_EXPORTER=otlp
export OTEL_LOGS_EXPORTER=otlp
export OTEL_EXPORTER_OTLP_PROTOCOL=http/protobuf
export OTEL_EXPORTER_OTLP_ENDPOINT=http://otel-collector:4318

# Optional - Enhanced tracking
export OTEL_LOG_USER_PROMPTS=1  # Privacy: Enable prompt logging
export OTEL_METRIC_EXPORT_INTERVAL=10000  # 10 second intervals
export OTEL_LOGS_EXPORT_INTERVAL=5000     # 5 second intervals

# Session tracking
export OTEL_METRICS_INCLUDE_SESSION_ID=true
export OTEL_METRICS_INCLUDE_ACCOUNT_UUID=true
```

---

## 2. Data Sources & Collection

### 2.1 Native Claude Code Metrics

Claude Code exports the following metrics via OpenTelemetry. Note that when exported to Prometheus via OTEL Collector, metric names are converted from dot notation to underscore notation with type suffixes.

| OTEL Metric Name | Prometheus Metric Name | Type | Labels | Description |
|------------------|------------------------|------|--------|-------------|
| `claude_code.token.usage` | `claude_code_token_usage_tokens_total` | Counter | `type`, `model`, `session.id` | Token consumption by category |
| `claude_code.cost.usage` | `claude_code_cost_usage_USD_total` | Counter | `model`, `session.id` | Estimated API costs |
| `claude_code.active_time.total` | `claude_code_active_time_seconds_total` | Counter | `session.id` | Active time in seconds |
| `claude_code.lines_of_code.count` | `claude_code_lines_of_code_count_total` | Counter | `type`, `session.id` | Lines added/removed |
| `claude_code.session.count` | `claude_code_session_count_total` | Counter | `session.id`, `terminal.type` | Session starts |
| `claude_code.commit.count` | `claude_code_commit_count_total` | Counter | `session.id` | Git commits created |
| `claude_code.pull_request.count` | `claude_code_pull_request_count_total` | Counter | `session.id` | PRs created |
| `claude_code.code_edit_tool.decision` | `claude_code_code_edit_tool_decision_total` | Counter | `tool`, `decision`, `language` | Edit accept/reject |

**Standard Attributes** (included in all metrics):
- `session.id` - Unique session identifier (controlled by `OTEL_METRICS_INCLUDE_SESSION_ID`)
- `organization.id` - Organization UUID (when authenticated)
- `user.account_uuid` - Account UUID (controlled by `OTEL_METRICS_INCLUDE_ACCOUNT_UUID`)
- `terminal.type` - Terminal type (e.g., `vscode`, `cursor`, `iTerm.app`)
- `app.version` - Claude Code version (controlled by `OTEL_METRICS_INCLUDE_VERSION`)

**Token Types** (`type` label):
- `input` - Tokens sent to API
- `output` - Tokens generated by Claude
- `cacheRead` - Tokens retrieved from cache
- `cacheCreation` - Tokens written to cache

**Lines of Code Types** (`type` label):
- `added` - Lines added
- `removed` - Lines removed

### 2.2 Event Logs (Loki)

Claude Code exports the following events via OpenTelemetry logs (when `OTEL_LOGS_EXPORTER` is configured):

| Event Name | Key Attributes | Use Case |
|------------|----------------|----------|
| `claude_code.user_prompt` | `prompt_length`, `prompt` (opt-in via `OTEL_LOG_USER_PROMPTS=1`) | Prompt analysis |
| `claude_code.tool_result` | `tool_name`, `success`, `duration_ms`, `error`, `decision`, `source`, `tool_parameters` | Tool execution analysis |
| `claude_code.api_request` | `model`, `cost_usd`, `duration_ms`, `input_tokens`, `output_tokens`, `cache_read_tokens`, `cache_creation_tokens` | API performance |
| `claude_code.api_error` | `model`, `error`, `status_code`, `duration_ms`, `attempt` | Error tracking |
| `claude_code.tool_decision` | `tool_name`, `decision` (`accept`/`reject`), `source` | Permission patterns |

**Decision Sources** (`source` attribute):
- `config` - Allowed by configuration
- `user_permanent` - User allowed permanently
- `user_temporary` - User allowed for session
- `user_abort` - User aborted operation
- `user_reject` - User rejected

**Tool Parameters** (for Bash tool):
- `bash_command`, `full_command`, `timeout`, `description`, `sandbox`

### 2.3 Derived Metrics (Computed in Grafana)

| Metric | Formula | Purpose |
|--------|---------|---------|
| Productivity Ratio | `cli_time / user_time` | How much Claude works vs you |
| Cost per Line | `total_cost / lines_added` | Code generation efficiency |
| Cache Hit Rate | `cache_read_tokens / total_input_tokens` | Context caching efficiency |
| Error Rate | `failed_tools / total_tools` | Tool reliability |
| Subagent Success Rate | `successful_tasks / total_tasks` | Task tool reliability |

---

## 3. Dashboard Sections

The dashboard is organized into **7 main sections**, each serving a specific monitoring objective.

### Section Overview

```
┌─────────────────────────────────────────────────────────────────────┐
│                     CLAUDE CODE METRICS DASHBOARD                    │
├─────────────────────────────────────────────────────────────────────┤
│  [1] EXECUTIVE SUMMARY        │  [2] COST & TOKEN ANALYTICS         │
│  - Active Sessions            │  - Cost by Model                    │
│  - Total Cost (24h)           │  - Token Breakdown                  │
│  - Error Rate                 │  - Cache Efficiency                 │
│  - Productivity Score         │  - Burn Rate Trend                  │
├───────────────────────────────┼─────────────────────────────────────┤
│  [3] TOOL EXECUTION           │  [4] SUBAGENT ANALYTICS             │
│  - Tool Usage by Type         │  - Agent Type Distribution          │
│  - Success/Failure Rates      │  - Per-Conversation Context         │
│  - Execution Duration         │  - Success Rate by Agent            │
│  - Error Heatmap              │  - Nested Agent Chains              │
├───────────────────────────────┼─────────────────────────────────────┤
│  [5] ERROR ANALYSIS           │  [6] PRODUCTIVITY METRICS           │
│  - Error Timeline             │  - Lines of Code                    │
│  - Errors by Tool             │  - Commits & PRs                    │
│  - Error Message Groups       │  - Developer Equivalence            │
│  - Retry Patterns             │  - Time Savings                     │
├─────────────────────────────────────────────────────────────────────┤
│  [7] SESSION & CONVERSATION CONTEXT                                  │
│  - Session Timeline                                                  │
│  - Per-Session Drill-down (Tools, Errors, Cost, Tokens)             │
│  - Conversation Flow Visualization                                   │
└─────────────────────────────────────────────────────────────────────┘
```

---

## 4. Metric Definitions

### 4.1 Token Types

| Type | Description |
|------|-------------|
| `input` | Tokens sent to the API (prompts, context) |
| `output` | Tokens generated by Claude |
| `cacheRead` | Tokens retrieved from cache (reduced cost) |
| `cacheCreation` | Tokens written to cache |

### 4.2 Tool Categories

| Category | Tools | Risk Level |
|----------|-------|------------|
| Read-Only | `Read`, `Glob`, `Grep`, `WebFetch`, `WebSearch` | Low |
| Write | `Edit`, `Write`, `NotebookEdit` | Medium |
| Execute | `Bash`, `Task` (subagents) | High |
| System | `AskUserQuestion`, `EnterPlanMode`, `ExitPlanMode` | Low |

### 4.3 Subagent Types

| Agent Type | Purpose | Typical Tools |
|------------|---------|---------------|
| `Explore` | Codebase exploration | Read, Glob, Grep |
| `Bash` | Command execution | Bash |
| `Plan` | Implementation planning | Read, Glob, Grep |
| `general-purpose` | Complex multi-step tasks | All |
| `code-reviewer` | Code review | Read, Grep |
| `silent-failure-hunter` | Error handling review | Read, Grep |

### 4.4 Decision Sources

| Source | Meaning |
|--------|---------|
| `config` | Allowed by configuration |
| `user_permanent` | User allowed permanently |
| `user_temporary` | User allowed for session |
| `user_reject` | User rejected |
| `user_abort` | User aborted operation |

---

## 5. Panel Specifications

### 5.1 Executive Summary Row

#### Panel: Active Sessions (Stat)
```promql
count(count by (session_id) (claude_code_session_count))
```
- **Type**: Stat
- **Unit**: Sessions
- **Thresholds**: Green (any), Yellow (>10), Red (>25)

#### Panel: Total Cost Today (Stat)
```promql
sum(increase(claude_code_cost_usage_USD_total[24h]))
```
- **Type**: Stat
- **Unit**: USD
- **Thresholds**: Green (<$10), Yellow (<$50), Red (>$50)

#### Panel: Tool Error Rate (Gauge)
```promql
(
  sum(count_over_time({service_name="claude-code", event_name="tool_result"} | json | success="false" [$__range]))
  /
  sum(count_over_time({service_name="claude-code", event_name="tool_result"} [$__range]))
) * 100
```
- **Type**: Gauge
- **Unit**: Percent
- **Thresholds**: Green (<5%), Yellow (<15%), Red (>15%)

#### Panel: Productivity Ratio (Stat)
```promql
sum(claude_code_active_time_seconds_total{type="cli"})
/
sum(claude_code_active_time_seconds_total{type="user"})
```
- **Type**: Stat
- **Unit**: Ratio (x:1)
- **Description**: "Claude works X times longer than your input time"

---

### 5.2 Cost & Token Analytics Row

#### Panel: Cost by Model (Time Series)
```promql
sum by (model) (increase(claude_code_cost_usage_USD_total[$__rate_interval]))
```
- **Type**: Time Series
- **Legend**: `{{model}}`
- **Stack**: On

#### Panel: Token Usage Breakdown (Pie Chart)
```promql
sum by (type) (increase(claude_code_token_usage_tokens_total[$__range]))
```
- **Type**: Pie Chart
- **Labels**: Input, Output, Cache Read, Cache Creation

#### Panel: Cache Efficiency (Gauge)
```promql
(
  sum(increase(claude_code_token_usage_tokens_total{type="cacheRead"}[$__range]))
  /
  sum(increase(claude_code_token_usage_tokens_total{type=~"input|cacheRead"}[$__range]))
) * 100
```
- **Type**: Gauge
- **Unit**: Percent
- **Thresholds**: Red (<50%), Yellow (<80%), Green (>80%)

#### Panel: Hourly Burn Rate (Time Series)
```promql
sum(rate(claude_code_cost_usage_USD_total[1h])) * 3600
```
- **Type**: Time Series
- **Unit**: USD/hour

#### Panel: Cost per 1K Lines (Stat)
```promql
(sum(increase(claude_code_cost_usage_USD_total[$__range]))
/
sum(sum_over_time(claude_code_lines_of_code_count_total{type="added"}[$__range]))) * 1000
```
- **Type**: Stat
- **Unit**: USD per 1K lines

---

### 5.3 Tool Execution Analytics Row

#### Panel: Tool Usage Distribution (Bar Chart)
```logql
sum by (tool_name) (count_over_time({service_name="claude-code", event_name="tool_result"} | json [$__range]))
```
- **Type**: Bar Chart
- **Sort**: Descending

#### Panel: Tool Success Rate (Table)
```logql
# Success rate by tool
sum by (tool_name) (count_over_time({service_name="claude-code", event_name="tool_result"} | json | success="true" [$__range]))
/
sum by (tool_name) (count_over_time({service_name="claude-code", event_name="tool_result"} | json [$__range]))
```
- **Type**: Table
- **Columns**: Tool Name, Total Calls, Success Rate, Avg Duration

#### Panel: Tool Execution Duration (Heatmap)
```logql
{service_name="claude-code", event_name="tool_result"}
| json
| unwrap duration_ms
| __error__=""
```
- **Type**: Heatmap
- **Y-Axis**: Tool Name
- **Color**: Duration (ms)

#### Panel: Tool Decision Patterns (Sankey)
```logql
sum by (tool_name, decision, decision_source) (
  count_over_time({service_name="claude-code", event_name="tool_decision"} | json [$__range])
)
```
- **Type**: Sankey (if available) or Stacked Bar
- **Flow**: Tool → Decision → Source

---

### 5.4 Subagent Analytics Row (CRITICAL)

#### Panel: Subagent Type Distribution (Pie Chart)
```logql
sum by (subagent_type) (
  count_over_time({service_name="claude-code", event_name="tool_result", tool_name="Task"} | json [$__range])
)
```
- **Type**: Pie Chart
- **Labels**: Explore, Bash, Plan, general-purpose, etc.

#### Panel: Subagent Success Rate by Type (Bar Gauge)
```logql
# Group by subagent_type, calculate success rate
sum by (subagent_type) (count_over_time({service_name="claude-code", event_name="tool_result", tool_name="Task"} | json | success="true" [$__range]))
/
sum by (subagent_type) (count_over_time({service_name="claude-code", event_name="tool_result", tool_name="Task"} | json [$__range]))
```
- **Type**: Bar Gauge
- **Thresholds**: Red (<70%), Yellow (<90%), Green (>90%)

#### Panel: Subagents per Conversation (Time Series)
```logql
sum by (session_id) (
  count_over_time({service_name="claude-code", event_name="tool_result", tool_name="Task"} | json [$__range])
)
```
- **Type**: Time Series
- **Legend**: `Session: {{session_id}}`

#### Panel: Subagent Error Analysis (Table)
```logql
{service_name="claude-code", event_name="tool_result", tool_name="Task"}
| json
| success="false"
| line_format "{{.subagent_type}}: {{.error_message}}"
```
- **Type**: Table
- **Columns**: Time, Session, Agent Type, Error Message, Duration

#### Panel: Subagent Chain Depth (Stat)
```logql
# Track nested subagent calls if available
max(
  count_over_time({service_name="claude-code", event_name="tool_result", tool_name="Task"} | json [$__range])
) by (session_id)
```
- **Type**: Stat
- **Description**: Max subagents in single session

---

### 5.5 Error Analysis Row (CRITICAL)

#### Panel: Error Timeline (Time Series)
```logql
sum(count_over_time({service_name="claude-code", event_name=~"tool_result|api_error"} | json | success="false" or event_name="api_error" [1m]))
```
- **Type**: Time Series
- **Color**: Red
- **Fill**: Gradient

#### Panel: Errors by Tool Type (Pie Chart)
```logql
sum by (tool_name) (
  count_over_time({service_name="claude-code", event_name="tool_result"} | json | success="false" [$__range])
)
```
- **Type**: Pie Chart
- **Color Scheme**: Reds

#### Panel: Error Message Groups (Table)
```logql
topk(10,
  sum by (error_message) (
    count_over_time({service_name="claude-code", event_name=~"tool_result|api_error"} | json | success="false" or status_code!="" [$__range])
  )
)
```
- **Type**: Table
- **Columns**: Error Message, Count, First Seen, Last Seen

#### Panel: API Error Status Codes (Bar Chart)
```logql
sum by (status_code) (
  count_over_time({service_name="claude-code", event_name="api_error"} | json [$__range])
)
```
- **Type**: Bar Chart
- **Labels**: 400, 401, 429, 500, 502, 503

#### Panel: Retry Patterns (Time Series)
```logql
{service_name="claude-code", event_name="api_error"}
| json
| attempt > 1
| sum by (attempt) (count_over_time([$__range]))
```
- **Type**: Time Series
- **Description**: Shows retry distribution

#### Panel: Error Correlation Matrix (Heatmap)
```logql
# Correlate errors with time of day and tool type
{service_name="claude-code", event_name="tool_result"}
| json
| success="false"
```
- **Type**: Heatmap
- **X-Axis**: Hour of Day
- **Y-Axis**: Tool Name

---

### 5.6 Productivity Metrics Row

#### Panel: Lines of Code (Time Series)
```promql
sum by (type) (sum_over_time(claude_code_lines_of_code_count_total[$__rate_interval]))
```
- **Type**: Time Series
- **Legend**: Added (green), Removed (red)

#### Panel: Commits Created (Stat)
```promql
sum(increase(claude_code_commit_count[$__range]))
```
- **Type**: Stat
- **Unit**: Commits

#### Panel: Pull Requests Created (Stat)
```promql
sum(increase(claude_code_pull_request_count[$__range]))
```
- **Type**: Stat
- **Unit**: PRs

#### Panel: Developer Equivalence (Gauge)
```promql
# Assuming 75 lines/hour baseline for human developer
sum(sum_over_time(claude_code_lines_of_code_count_total{type="added"}[$__range])) / 75
```
- **Type**: Gauge
- **Unit**: Hours
- **Description**: "Equivalent human developer hours"

#### Panel: Code Acceptance Rate (Gauge)
```promql
sum(claude_code_code_edit_tool_decision{decision="accept"})
/
sum(claude_code_code_edit_tool_decision)
```
- **Type**: Gauge
- **Unit**: Percent
- **Thresholds**: Red (<60%), Yellow (<80%), Green (>80%)

---

### 5.7 Session & Conversation Context Row

#### Panel: Session Timeline (Timeline)
```logql
{service_name="claude-code"}
| json
| line_format "{{.event_name}}: {{.tool_name}}"
```
- **Type**: Timeline / State Timeline
- **Group By**: session_id

#### Panel: Session Drill-down (Table with Links)
```promql
# Aggregate metrics by session
sum by (session_id) (claude_code_cost_usage_USD_total)
```
- **Type**: Table
- **Columns**: Session ID, Start Time, Duration, Cost, Tokens, Tools Used, Errors
- **Links**: Drill-down to session detail view

#### Panel: Conversation Flow (Node Graph)
- **Type**: Node Graph (if supported)
- **Nodes**: User Prompt → Claude Response → Tool Calls → Subagents
- **Edges**: Sequence of events

#### Panel: Session Context Variables (Table)
```logql
{service_name="claude-code", event_name="user_prompt"}
| json
```
- **Type**: Table
- **Columns**: Session, Prompt Length, Timestamp
- **Note**: Requires `OTEL_LOG_USER_PROMPTS=1`

---

## 6. Alerting Rules

### 6.1 Cost Alerts

```yaml
groups:
  - name: claude-code-cost
    rules:
      - alert: HighHourlyCost
        expr: sum(rate(claude_code_cost_usage_USD_total[1h])) * 3600 > 10
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Claude Code hourly cost exceeds $10/hour"

      - alert: DailyCostThreshold
        expr: sum(increase(claude_code_cost_usage_USD_total[24h])) > 100
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Daily Claude Code cost exceeds $100"
```

### 6.2 Error Alerts

```yaml
      - alert: HighToolErrorRate
        expr: |
          (sum(count_over_time({service_name="claude-code", event_name="tool_result"} | json | success="false" [5m]))
          / sum(count_over_time({service_name="claude-code", event_name="tool_result"} [5m]))) > 0.15
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "Tool error rate exceeds 15%"

      - alert: SubagentFailureSpike
        expr: |
          sum(count_over_time({service_name="claude-code", event_name="tool_result", tool_name="Task"} | json | success="false" [10m])) > 5
        for: 1m
        labels:
          severity: warning
        annotations:
          summary: "Multiple subagent failures detected"

      - alert: APIErrorSpike
        expr: |
          sum(count_over_time({service_name="claude-code", event_name="api_error"} [5m])) > 10
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "API error spike detected"
```

### 6.3 Performance Alerts

```yaml
      - alert: SlowToolExecution
        expr: |
          avg(duration_ms) by (tool_name) > 30000
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Tool {{ $labels.tool_name }} averaging >30s execution"

      - alert: LowCacheEfficiency
        expr: |
          (sum(rate(claude_code_token_usage_tokens_total{type="cacheRead"}[1h]))
          / sum(rate(claude_code_token_usage_tokens_total{type=~"input|cacheRead"}[1h]))) < 0.5
        for: 30m
        labels:
          severity: info
        annotations:
          summary: "Cache hit rate below 50% - consider conversation context"
```

---

## 7. Implementation Guide

### 7.1 Prerequisites

1. **Prometheus** with OTLP receiver enabled:
   ```bash
   prometheus --web.enable-otlp-receiver --enable-feature=otlp-deltatocumulative
   ```

2. **Loki** for log aggregation (already deployed in monitoring namespace)

3. **Grafana** with datasources configured (already deployed)

### 7.2 OpenTelemetry Collector Configuration

```yaml
# otel-collector-config.yaml
receivers:
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317
      http:
        endpoint: 0.0.0.0:4318

processors:
  batch:
    timeout: 10s
    send_batch_size: 1024
  memory_limiter:
    check_interval: 1s
    limit_mib: 512
    spike_limit_mib: 128

exporters:
  # IMPORTANT: Do NOT add 'namespace' - Claude Code already prefixes metrics with "claude_code_"
  prometheus:
    endpoint: "0.0.0.0:8889"
    const_labels:
      collector: otel-collector
    resource_to_telemetry_conversion:
      enabled: true

  # Prometheus remote write for pushing metrics directly
  prometheusremotewrite:
    endpoint: "http://prometheus-server.monitoring.svc.cluster.local:80/api/v1/write"
    tls:
      insecure: true

  # OTLP HTTP exporter for logs to Loki
  otlphttp/loki:
    endpoint: "http://loki-gateway.monitoring.svc.cluster.local:80/otlp"
    tls:
      insecure: true

  # Debug exporter for troubleshooting
  debug:
    verbosity: basic
    sampling_initial: 5
    sampling_thereafter: 200

service:
  pipelines:
    metrics:
      receivers: [otlp]
      processors: [memory_limiter, batch]
      exporters: [prometheus, prometheusremotewrite]
    logs:
      receivers: [otlp]
      processors: [memory_limiter, batch]
      exporters: [otlphttp/loki, debug]
```

**Important Notes:**
- Do NOT add `namespace` to the prometheus exporter - Claude Code metrics already have the `claude_code_` prefix
- The `otlphttp/loki` exporter uses Loki's native OTLP endpoint (`/otlp`) for better compatibility
- Remote write provides redundancy alongside Prometheus scraping

### 7.3 Deployment Order

1. Deploy OpenTelemetry Collector to `monitoring` namespace
2. Configure Claude Code environment variables
3. Import Grafana dashboard JSON
4. Configure alerting rules
5. Test with sample Claude Code session

### 7.4 Dashboard Variables

Define these template variables in Grafana:

| Variable | Query | Multi-select |
|----------|-------|--------------|
| `session_id` | `label_values(claude_code_session_count, session_id)` | Yes |
| `model` | `label_values(claude_code_cost_usage_USD_total, model)` | Yes |
| `tool` | `label_values(tool_name)` | Yes |
| `terminal` | `label_values(claude_code_session_count, terminal_type)` | Yes |

### 7.5 Grafana Dashboard JSON Structure

```json
{
  "title": "Claude Code Metrics Dashboard",
  "uid": "claude-code-metrics",
  "tags": ["claude", "ai", "monitoring", "productivity"],
  "templating": {
    "list": [
      {"name": "session_id", "type": "query"},
      {"name": "model", "type": "query"},
      {"name": "tool", "type": "query"}
    ]
  },
  "panels": [
    // 7 rows as specified above
  ],
  "refresh": "30s",
  "time": {
    "from": "now-24h",
    "to": "now"
  }
}
```

---

## Appendix A: Key Insights from Research

### Community Best Practices

1. **Multi-tool strategy**: Combine real-time dashboards with historical analysis
2. **Context matters**: Track metrics per-session/conversation for meaningful insights
3. **Error focus**: Tool failure rates are the #1 indicator of productivity blockers
4. **Cost visibility**: Token-based tracking enables proactive cost management
5. **Subagent monitoring**: Task tool failures often cascade - track at agent-type level

### ROI Metrics

- **Developer Equivalence**: `lines_added / 75` (assuming 75 lines/hour human baseline)
- **Cost Efficiency**: `lines_added / cost_usd`
- **Productivity Ratio**: `cli_active_time / user_active_time`
- **Max Plan Value**: `actual_cost / (200/30 * days_in_range)` for $200/month plan

### Privacy Considerations

- User prompts are **not logged by default** - enable with `OTEL_LOG_USER_PROMPTS=1`
- API keys and file contents are **never included** in telemetry
- Session IDs can be disabled for privacy with `OTEL_METRICS_INCLUDE_SESSION_ID=false`

---

## Appendix B: References

### Official Documentation
1. **[Claude Code Monitoring Documentation](https://code.claude.com/docs/en/monitoring-usage)** - Official reference for all metrics, events, and configuration options
2. **[Claude Code ROI Measurement Guide](https://github.com/anthropics/claude-code-monitoring-guide)** - Official repo with Docker Compose configs, Prometheus/OTEL setups, and productivity reports

### Community Resources
3. [centminmod/claude-code-opentelemetry-setup](https://github.com/centminmod/claude-code-opentelemetry-setup)
4. [Real-Time Dashboards for Claude Code Metrics](https://dev.to/mikelane/how-i-built-real-time-dashboards-for-claude-code-metrics-with-otel-prometheus-and-grafana-4e7o)
5. [Track Claude Code Usage with Grafana Cloud](https://quesma.com/blog/track-claude-code-usage-and-limits-with-grafana-cloud/)
6. [Claude Code Monitoring with OpenTelemetry (SigNoz)](https://signoz.io/blog/claude-code-monitoring-with-opentelemetry/)

### Platform-Specific
7. [Claude Code Monitoring for Amazon Bedrock](https://github.com/aws-solutions-library-samples/guidance-for-claude-code-with-amazon-bedrock/blob/main/assets/docs/MONITORING.md)

---

## Appendix C: Troubleshooting Guide

### Issues Discovered and Resolved (2026-01-25)

This section documents issues encountered during implementation and their resolutions.

---

### Issue 1: Dashboard Showing Only Session Timeline Data

**Symptom**: Only the "Session Timeline" panel (which uses Loki) showed data. All Prometheus-based panels were empty.

**Root Cause**: The OTEL collector's Prometheus exporter was configured with `namespace: claude_code`, but Claude Code already exports metrics with the `claude_code_` prefix. This resulted in double-prefixed metric names like `claude_code_claude_code_token_usage_tokens_total`, which didn't match dashboard queries.

**Resolution**: Removed the `namespace` setting from the OTEL collector's Prometheus exporter configuration:

```yaml
# BEFORE (incorrect)
exporters:
  prometheus:
    endpoint: "0.0.0.0:8889"
    namespace: claude_code  # This caused double-prefixing!

# AFTER (correct)
exporters:
  prometheus:
    endpoint: "0.0.0.0:8889"
    # No namespace - Claude Code already prefixes metrics
```

**Files Changed**: `manifests/monitoring/otel-collector-configmap.yaml`

---

### Issue 2: Expected Metrics Not Available

**Symptom**: Several dashboard panels queried for metrics that don't exist.

**Root Cause**: The original specification assumed Claude Code exported more metrics than it actually does.

**Actual Claude Code Prometheus Metrics (verified via official docs and live testing)**:

According to the [official Claude Code monitoring documentation](https://code.claude.com/docs/en/monitoring-usage), the following metrics are exported:

| OTEL Name | Prometheus Name | Type | Labels |
|-----------|-----------------|------|--------|
| `claude_code.token.usage` | `claude_code_token_usage_tokens_total` | Counter | `type`, `model`, `session.id` |
| `claude_code.cost.usage` | `claude_code_cost_usage_USD_total` | Counter | `model`, `session.id` |
| `claude_code.active_time.total` | `claude_code_active_time_seconds_total` | Counter | `session.id` |
| `claude_code.session.count` | `claude_code_session_count_total` | Counter | `session.id`, `terminal.type` |
| `claude_code.lines_of_code.count` | `claude_code_lines_of_code_count_total` | Counter | `type`, `session.id` |
| `claude_code.commit.count` | `claude_code_commit_count_total` | Counter | `session.id` |
| `claude_code.pull_request.count` | `claude_code_pull_request_count_total` | Counter | `session.id` |
| `claude_code.code_edit_tool.decision` | `claude_code_code_edit_tool_decision_total` | Counter | `tool`, `decision`, `language` |

**Note**: Some metrics may not appear until the corresponding action occurs (e.g., `commit.count` only appears after a commit is made via Claude Code).

**Resolution**: Dashboard panels should query the correct Prometheus metric names (with `_total` suffix for counters) and consider that some metrics may have zero values initially.

---

### Issue 3: Missing Prometheus Scrape Configuration

**Symptom**: OTEL collector metrics endpoint (port 8889) was not being scraped by Prometheus.

**Root Cause**: Although the OTEL collector had `prometheus.io/scrape: "true"` annotations, the annotation-based discovery wasn't working reliably.

**Resolution**: Added explicit scrape job to Prometheus configuration:

```yaml
# templates/prometheus_helm_values.yaml.tpl
extraScrapeConfigs: |
  - job_name: 'otel-collector'
    scrape_interval: 15s
    static_configs:
      - targets: ['otel-collector.monitoring.svc.cluster.local:8889']
    metric_relabel_configs:
      - source_labels: [__name__]
        regex: 'claude.*|otelcol.*'
        action: keep
```

**Files Changed**: `templates/prometheus_helm_values.yaml.tpl`

---

### Issue 4: Prometheus Remote Write Endpoint Verification

**Symptom**: Uncertainty about whether remote write was working.

**Diagnosis Steps**:
```bash
# Check OTEL collector logs for remote write status
oc logs -n monitoring deployment/otel-collector | grep -i "remote\|prometheus"

# Verify Prometheus service name
oc get svc -n monitoring | grep prometheus

# Query Prometheus directly for claude metrics
oc exec -n monitoring deployment/prometheus-server -- \
  wget -qO- 'http://localhost:9090/api/v1/query?query={__name__=~"claude.*"}'
```

**Resolution**: The remote write endpoint was correct (`prometheus-server.monitoring.svc.cluster.local:80/api/v1/write`). The issue was the namespace prefix causing metric name mismatch.

---

### Verification Commands

After applying fixes, verify with these commands:

```bash
# 1. Check OTEL collector is running
oc get pods -n monitoring -l app=otel-collector

# 2. Check for Claude metrics in Prometheus
oc exec -n monitoring deployment/prometheus-server -- \
  wget -qO- 'http://localhost:9090/api/v1/query?query={__name__=~"claude_code.*"}' | \
  jq '.data.result | length'
# Expected: > 0

# 3. List available Claude Code metric names
oc exec -n monitoring deployment/prometheus-server -- \
  wget -qO- 'http://localhost:9090/api/v1/query?query={__name__=~"claude_code.*"}' | \
  jq -r '.data.result[].metric.__name__' | sort -u
# Expected metrics (depending on activity):
#   claude_code_active_time_seconds_total
#   claude_code_code_edit_tool_decision_total
#   claude_code_commit_count_total
#   claude_code_cost_usage_USD_total
#   claude_code_lines_of_code_count_total
#   claude_code_pull_request_count_total
#   claude_code_session_count_total
#   claude_code_token_usage_tokens_total

# 4. Check Loki has Claude Code logs
oc exec -n monitoring deployment/loki-gateway -- \
  wget -qO- 'http://localhost:80/loki/api/v1/query?query={service_name="claude-code"}'

# 5. Check specific metric values
oc exec -n monitoring deployment/prometheus-server -- \
  wget -qO- 'http://localhost:9090/api/v1/query?query=sum(claude_code_cost_usage_USD_total)' | \
  jq '.data.result[0].value[1]'
# Returns: total cost in USD
```

---

### Issue 5: Loki Not Receiving Logs via OTLP

**Symptom**: Tool Execution Analytics, Subagent Analytics, Error Analysis, and Productivity Metrics panels (which query Loki) showed no data despite OTEL collector reporting successful log exports.

**Root Cause**: The OTEL collector was configured to send logs to Loki's `/otlp` endpoint, but Loki didn't have OTLP ingestion enabled. The logs were being sent but Loki wasn't accepting them.

**Resolution**: Added OTLP configuration to Loki Helm values:

```yaml
# templates/loki_helm_values.yaml.tpl
loki:
  # Enable OTLP log ingestion
  distributor:
    otlp_config:
      default_resource_attributes_as_index_labels:
        - service.name
        - service.instance.id
        - deployment.environment

  limits_config:
    # ... other settings ...
    # Allow OTLP structured metadata
    allow_structured_metadata: true
    # OTLP config for resource attributes to index as labels
    otlp_config:
      resource_attributes:
        attributes_config:
          - action: index_label
            attributes:
              - service.name
              - deployment.environment
              - level
```

**Files Changed**: `templates/loki_helm_values.yaml.tpl`

---

### Issue 6: Malformed SCC Blocking Pod Creation (OpenShift)

**Symptom**: Loki pods failed to create with error: `pods is forbidden: error creating provider for SCC loki-minio in namespace monitoring: MustRunAs requires a UID`

**Root Cause**: The Loki Helm chart's bundled MinIO subchart created a malformed SecurityContextConstraints (SCC) resource that specified `MustRunAs` without a UID value.

**Resolution**:
1. Disable SCC creation in Helm values (already configured):
   ```yaml
   minio:
     securityContextConstraints:
       enabled: false
   ```

2. If the SCC was already created, delete it manually:
   ```bash
   oc delete scc loki-minio
   ```

3. Restart Loki workloads:
   ```bash
   oc rollout restart statefulset -n monitoring -l app.kubernetes.io/name=loki
   oc rollout restart deployment -n monitoring -l app.kubernetes.io/name=loki
   ```

**Note**: This issue reoccurs on Helm upgrades if the chart creates the SCC before the `enabled: false` setting takes effect. Monitor and delete the SCC if it reappears.

---

### Configuration Files Reference

| File | Purpose | Key Settings |
|------|---------|--------------|
| `otel-collector-configmap.yaml` | OTEL Collector config | Prometheus exporter without namespace, OTLP HTTP exporter for Loki |
| `prometheus_helm_values.yaml.tpl` | Prometheus config | Remote write receiver enabled, OTEL collector scrape job |
| `loki_helm_values.yaml.tpl` | Loki config | OTLP ingestion enabled, SCC creation disabled |
| `claude-code-otel-env.sh` | Client environment vars | CLAUDE_CODE_ENABLE_TELEMETRY=1, OTEL endpoints |

---

### Architecture Validation

Confirmed working data flow:
```
Claude Code (OTLP/HTTP)
    ↓
OTEL Collector (port 4318)
    ├── Prometheus Exporter (port 8889) ──→ Prometheus (scrape)
    ├── Remote Write ──→ Prometheus (/api/v1/write)
    └── OTLP/HTTP ──→ Loki (/otlp)
           ↓
       Grafana Dashboard
```

---

## Version History

| Version | Date | Changes |
|---------|------|---------|
| 1.0 | 2026-01-25 | Initial specification |
| 1.1 | 2026-01-25 | Added Troubleshooting Guide (Appendix C), corrected actual metric names, documented OTEL collector namespace fix |
| 1.2 | 2026-01-25 | Added Loki OTLP ingestion fix (Issue 5), documented OpenShift SCC issue (Issue 6) |
